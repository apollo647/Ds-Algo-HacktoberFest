{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        file = os.path.join(dirname, filename)\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Importing necessary libraries."},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.layers import Input, Dense, Flatten\nfrom keras import Model\nfrom keras.applications.vgg16 import VGG16\nfrom keras.preprocessing import image\nfrom keras.models import Sequential","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we are using VGG16 architecture, it expects the size of 224 by 224(Although, you can set your own size). We will set image size."},{"metadata":{"trusted":true},"cell_type":"code","source":"image_size = [224, 224]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vgg = VGG16(input_shape = image_size + [3], weights = 'imagenet', include_top =  False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The first argument is the shape of input image plus **3**(as image is colured[RBG], for black_and_white add **1**).\nThe second one is the weights eqaul to imagenet. And,\nas we know it gives 1000 outputs. Third one excludes the top layer."},{"metadata":{"trusted":true},"cell_type":"code","source":"for layer in vgg.layers:\n    layer.trainable = False","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Some of the layers of VGG16 are already trained. To train them again is not a good practice. Thereby making it False"},{"metadata":{"trusted":true},"cell_type":"code","source":"from glob import glob\nfolders = glob('/kaggle/input/tomato/New Plant Diseases Dataset(Augmented)/train/*')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"folders\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Flattening the output layer"},{"metadata":{"trusted":true},"cell_type":"code","source":"x = Flatten()(vgg.output)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prediction = Dense(len(folders), activation = 'softmax')(x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Model(inputs = vgg.input, outputs = prediction)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Compiling the model"},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Generating more images"},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data_gen = ImageDataGenerator(rescale = 1./255, shear_range = 0.2, zoom_range = 0.2, horizontal_flip = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data_gen = ImageDataGenerator(rescale = 1./255)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_set = train_data_gen.flow_from_directory('/kaggle/input/tomato/New Plant Diseases Dataset(Augmented)/train/', target_size = (224,224), batch_size = 32, class_mode = 'categorical')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_set = test_data_gen.flow_from_directory('/kaggle/input/tomato/New Plant Diseases Dataset(Augmented)/valid/', target_size = (224,224), batch_size = 32, class_mode = 'categorical')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Fitting the model"},{"metadata":{"trusted":true},"cell_type":"code","source":"mod = model.fit_generator(\n  train_set,\n  validation_data=test_set,\n  epochs=10,\n  steps_per_epoch=len(train_set),\n  validation_steps=len(test_set)\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.plot(mod.history['loss'], label='train loss')\nplt.plot(mod.history['val_loss'], label='val loss')\nplt.legend()\nplt.show()\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(mod.history['accuracy'], label='train accuracy')\nplt.plot(mod.history['val_accuracy'], label='val_accuracy')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}